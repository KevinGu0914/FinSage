#!/usr/bin/env python3
"""
MARFT V4 è®­ç»ƒå¥½çš„ LoRA æƒé‡è¯„ä¼°è„šæœ¬

åœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼° Aggressive å’Œ Balanced ç­–ç•¥çš„æ€§èƒ½ï¼Œ
å¹¶ç”Ÿæˆè¯¦ç»†çš„ç›‘æ§æ—¥å¿—ã€‚

Usage:
    python scripts/evaluate_trained_lora.py --checkpoint aggressive_final --test-start 2024-10-01 --test-end 2024-11-30
    python scripts/evaluate_trained_lora.py --checkpoint balanced_final --test-start 2024-10-01 --test-end 2024-11-30
"""

import os
import sys

# ç¡®ä¿ finsage æ¨¡å—å¯å¯¼å…¥ (å…¼å®¹æœ¬åœ°å’Œè¿œç¨‹æœåŠ¡å™¨)
_script_dir = os.path.dirname(os.path.abspath(__file__))
_project_root = os.path.dirname(_script_dir)
sys.path.insert(0, _project_root)

# è¿œç¨‹æœåŠ¡å™¨å¤‡ç”¨è·¯å¾„
if not os.path.exists(os.path.join(_project_root, 'finsage')):
    for fallback in ['/root/finsage', '/root/FinSage', '/home/finsage']:
        if os.path.exists(os.path.join(fallback, 'finsage')):
            sys.path.insert(0, fallback)
            break

import json
import time
import logging
from datetime import datetime
from typing import Dict, List, Any, Optional
from collections import defaultdict
import traceback
import numpy as np
import pandas as pd
import torch

# Load environment variables
from dotenv import load_dotenv
load_dotenv()


# ============================================================
# Bug æ£€æµ‹ä¸è¿½è¸ªç³»ç»Ÿ
# ============================================================

class BugTracker:
    """è¿½è¸ªè¯„ä¼°è¿‡ç¨‹ä¸­å‘ç°çš„æ‰€æœ‰æ½œåœ¨é—®é¢˜"""

    def __init__(self, logger: logging.Logger):
        self.logger = logger
        self.issues = defaultdict(list)  # category -> [issues]
        self.warnings = defaultdict(int)  # warning_type -> count
        self.expert_call_counts = defaultdict(int)
        self.meta_agent_outputs = defaultdict(list)
        self.error_samples = []  # ä¿å­˜å‰10ä¸ªé”™è¯¯æ ·æœ¬

    def log_issue(self, category: str, message: str, severity: str = "WARNING",
                  date: str = None, extra: dict = None):
        """è®°å½•ä¸€ä¸ªé—®é¢˜"""
        issue = {
            "message": message,
            "severity": severity,
            "date": date,
            "timestamp": datetime.now().isoformat(),
            "extra": extra or {}
        }
        self.issues[category].append(issue)

        if severity == "ERROR":
            self.logger.error(f"[BUG-{category}] {message}")
            if len(self.error_samples) < 10:
                self.error_samples.append(issue)
        elif severity == "WARNING":
            self.logger.warning(f"[BUG-{category}] {message}")
            self.warnings[category] += 1
        else:
            self.logger.debug(f"[BUG-{category}] {message}")

    def track_expert_call(self, role: str, success: bool, output: dict = None, error: str = None):
        """è¿½è¸ªExpertè°ƒç”¨"""
        self.expert_call_counts[role] += 1
        if not success:
            self.log_issue("EXPERT_CALL_FAILED", f"{role} è°ƒç”¨å¤±è´¥: {error}",
                          severity="ERROR", extra={"role": role, "error": error})

        # è¿½è¸ªMeta-Level Agentè¾“å‡º
        if role in ["Portfolio_Manager", "Hedging_Agent", "Position_Sizing_Agent", "Risk_Controller"]:
            self.meta_agent_outputs[role].append(output or {})

    def validate_expert_chain(self, all_actions: dict, expected_experts: list):
        """éªŒè¯Expert Chainæ˜¯å¦å®Œæ•´"""
        missing = []
        for expert in expected_experts:
            if expert not in all_actions:
                missing.append(expert)
                self.log_issue("MISSING_EXPERT", f"Experté“¾ç¼ºå¤±: {expert}",
                              severity="ERROR")

        # æ£€æŸ¥æ˜¯å¦æœ‰æ„å¤–çš„Expert
        for expert in all_actions:
            if expert not in expected_experts:
                self.log_issue("UNEXPECTED_EXPERT", f"æ„å¤–çš„Expert: {expert}",
                              severity="WARNING")

        return len(missing) == 0

    def validate_meta_agent_output(self, role: str, output: dict, date: str):
        """éªŒè¯Meta-Level Agentè¾“å‡ºæ ¼å¼"""
        if role == "Risk_Controller":
            # å¿…é¡»æœ‰ veto æˆ– risk_level
            if "veto" not in output and "risk_level" not in output and "action" not in output:
                self.log_issue("INVALID_OUTPUT",
                              f"Risk_Controller è¾“å‡ºç¼ºå°‘ veto/risk_level/action å­—æ®µ",
                              severity="WARNING", date=date, extra={"output": str(output)[:200]})
                return False

        elif role == "Position_Sizing_Agent":
            # å¿…é¡»æœ‰ risk_budget æˆ– position_scale
            if "risk_budget" not in output and "position_scale" not in output and "action" not in output:
                self.log_issue("INVALID_OUTPUT",
                              f"Position_Sizing_Agent è¾“å‡ºç¼ºå°‘ risk_budget/position_scale å­—æ®µ",
                              severity="WARNING", date=date, extra={"output": str(output)[:200]})
                return False

        elif role == "Portfolio_Manager":
            # æ£€æŸ¥æ˜¯å¦æœ‰é…ç½®å»ºè®®
            if "target_allocation" not in output and "allocation" not in output and "action" not in output:
                self.log_issue("INVALID_OUTPUT",
                              f"Portfolio_Manager è¾“å‡ºç¼ºå°‘é…ç½®å»ºè®®",
                              severity="WARNING", date=date, extra={"output": str(output)[:200]})
                return False

        elif role == "Hedging_Agent":
            # æ£€æŸ¥æ˜¯å¦æœ‰å¯¹å†²å»ºè®®
            if "hedge_strategy" not in output and "hedge_ratio" not in output and "action" not in output:
                self.log_issue("INVALID_OUTPUT",
                              f"Hedging_Agent è¾“å‡ºç¼ºå°‘å¯¹å†²å»ºè®®",
                              severity="WARNING", date=date, extra={"output": str(output)[:200]})
                return False

        return True

    def check_data_issues(self, obs, date: str, history: pd.DataFrame = None):
        """æ£€æŸ¥è¾“å…¥æ•°æ®é—®é¢˜"""
        # obs å¯èƒ½æ˜¯ string (prompt) æˆ– dict
        if isinstance(obs, str):
            # å¦‚æœæ˜¯ stringï¼Œä» history æ£€æŸ¥æ•°æ®é—®é¢˜
            if history is not None and isinstance(history, pd.DataFrame):
                if history.empty:
                    self.log_issue("DATA_MISSING", "history DataFrameä¸ºç©º",
                                  severity="WARNING", date=date)
                elif len(history) < 5:
                    self.log_issue("DATA_INSUFFICIENT", f"historyæ•°æ®ä¸è¶³: {len(history)}è¡Œ",
                                  severity="WARNING", date=date)
            return

        market_data = obs.get("market_data", {}) if isinstance(obs, dict) else {}

        # æ£€æŸ¥ä»·æ ¼æ•°æ®
        prices = market_data.get("prices", {})
        if not prices:
            self.log_issue("DATA_MISSING", "å¸‚åœºæ•°æ®ç¼ºå°‘ä»·æ ¼",
                          severity="ERROR", date=date)

        # æ£€æŸ¥æ”¶ç›Šç‡æ•°æ®
        returns = market_data.get("returns", {})
        if isinstance(returns, pd.DataFrame):
            if returns.empty:
                self.log_issue("DATA_MISSING", "æ”¶ç›Šç‡æ•°æ®ä¸ºç©ºDataFrame",
                              severity="WARNING", date=date)
        elif isinstance(returns, dict):
            if len(returns) == 0:
                self.log_issue("DATA_MISSING", "æ”¶ç›Šç‡æ•°æ®ä¸ºç©ºdict",
                              severity="WARNING", date=date)

        # æ£€æŸ¥returns_window
        returns_window = market_data.get("returns_window")
        if returns_window is None:
            self.log_issue("DATA_MISSING", "ç¼ºå°‘ returns_window å­—æ®µ",
                          severity="WARNING", date=date)
        elif isinstance(returns_window, pd.DataFrame) and returns_window.empty:
            self.log_issue("DATA_MISSING", "returns_window ä¸ºç©º",
                          severity="WARNING", date=date)

    def generate_summary(self) -> dict:
        """ç”Ÿæˆé—®é¢˜æ‘˜è¦"""
        summary = {
            "total_issues": sum(len(v) for v in self.issues.values()),
            "issues_by_category": {k: len(v) for k, v in self.issues.items()},
            "warnings_by_type": dict(self.warnings),
            "expert_call_counts": dict(self.expert_call_counts),
            "error_samples": self.error_samples[:5],
            "meta_agent_analysis": {}
        }

        # åˆ†æMeta-Level Agent
        expected_meta = ["Portfolio_Manager", "Hedging_Agent", "Position_Sizing_Agent", "Risk_Controller"]
        for agent in expected_meta:
            outputs = self.meta_agent_outputs.get(agent, [])
            summary["meta_agent_analysis"][agent] = {
                "total_calls": len(outputs),
                "non_empty_outputs": sum(1 for o in outputs if o),
                "sample_output": outputs[0] if outputs else None
            }

        return summary

    def print_summary(self):
        """æ‰“å°é—®é¢˜æ‘˜è¦"""
        summary = self.generate_summary()

        self.logger.info("\n" + "=" * 80)
        self.logger.info(" ğŸ› BUG æ£€æµ‹æŠ¥å‘Š")
        self.logger.info("=" * 80)

        self.logger.info(f"\nğŸ“Š é—®é¢˜ç»Ÿè®¡:")
        self.logger.info(f"  æ€»é—®é¢˜æ•°: {summary['total_issues']}")
        for cat, count in summary['issues_by_category'].items():
            self.logger.info(f"  - {cat}: {count}")

        self.logger.info(f"\nğŸ“ Expert è°ƒç”¨ç»Ÿè®¡:")
        for expert, count in summary['expert_call_counts'].items():
            status = "âœ…" if count > 0 else "âŒ"
            self.logger.info(f"  {status} {expert}: {count} æ¬¡")

        # æ£€æŸ¥Meta-Level Agents
        self.logger.info(f"\nğŸ¯ Meta-Level Agent åˆ†æ:")
        for agent, analysis in summary['meta_agent_analysis'].items():
            status = "âœ…" if analysis['total_calls'] > 0 else "âŒ [BUG]"
            self.logger.info(f"  {status} {agent}:")
            self.logger.info(f"      è°ƒç”¨æ¬¡æ•°: {analysis['total_calls']}")
            self.logger.info(f"      æœ‰æ•ˆè¾“å‡º: {analysis['non_empty_outputs']}")
            if analysis['sample_output']:
                self.logger.info(f"      æ ·ä¾‹è¾“å‡º: {str(analysis['sample_output'])[:100]}...")

        # æ£€æµ‹å…³é”®Bug
        self.logger.info(f"\nğŸš¨ å…³é”®é—®é¢˜æ£€æµ‹:")
        critical_bugs = []

        # Bug 1: Meta-Level Agents æœªè°ƒç”¨
        for agent in ["Portfolio_Manager", "Hedging_Agent", "Position_Sizing_Agent", "Risk_Controller"]:
            if summary['expert_call_counts'].get(agent, 0) == 0:
                critical_bugs.append(f"{agent} ä»æœªè¢«è°ƒç”¨!")

        # Bug 2: Expert Chain ä¸å®Œæ•´
        expected_all = ["Stock_Expert", "Bond_Expert", "Commodity_Expert", "REITs_Expert",
                       "Crypto_Expert", "Portfolio_Manager", "Hedging_Agent",
                       "Position_Sizing_Agent", "Risk_Controller"]
        missing = [e for e in expected_all if summary['expert_call_counts'].get(e, 0) == 0]
        if missing:
            critical_bugs.append(f"ç¼ºå¤±çš„Experts: {missing}")

        if critical_bugs:
            for bug in critical_bugs:
                self.logger.error(f"  âŒ {bug}")
        else:
            self.logger.info("  âœ… æœªå‘ç°å…³é”®Bug")

        return summary

# ============================================================
# è¯¦ç»†ç›‘æ§æ—¥å¿—é…ç½®
# ============================================================

def setup_detailed_logging(log_file: str) -> logging.Logger:
    """è®¾ç½®è¯¦ç»†ç›‘æ§æ—¥å¿—"""
    logger = logging.getLogger("LoRAEval")
    logger.setLevel(logging.DEBUG)

    # æ¸…é™¤ç°æœ‰handlers
    logger.handlers = []

    # æ–‡ä»¶handler - è¯¦ç»†æ—¥å¿—
    file_handler = logging.FileHandler(log_file, mode='w', encoding='utf-8')
    file_handler.setLevel(logging.DEBUG)
    file_formatter = logging.Formatter(
        "%(asctime)s [%(levelname)s] [%(funcName)s:%(lineno)d] %(message)s",
        datefmt="%Y-%m-%d %H:%M:%S"
    )
    file_handler.setFormatter(file_formatter)

    # æ§åˆ¶å°handler - INFOçº§åˆ«
    console_handler = logging.StreamHandler()
    console_handler.setLevel(logging.INFO)
    console_formatter = logging.Formatter(
        "%(asctime)s [%(levelname)s] %(message)s",
        datefmt="%H:%M:%S"
    )
    console_handler.setFormatter(console_formatter)

    logger.addHandler(file_handler)
    logger.addHandler(console_handler)

    return logger


# ============================================================
# èµ„äº§ç±»åˆ«å’Œç¬¦å·é…ç½®
# ============================================================

ASSETS = {
    "stocks": ["SPY", "QQQ", "AAPL", "MSFT", "GOOGL", "AMZN", "NVDA", "META"],
    "bonds": ["TLT", "LQD", "HYG", "AGG"],
    "commodities": ["GLD", "SLV", "USO", "UNG"],
    "reits": ["VNQ", "IYR", "XLRE"],
    "crypto": ["BTC-USD", "ETH-USD"],
}

# èµ„äº§ç±»åˆ«æƒé‡é…ç½® - æ§åˆ¶å„ç±»èµ„äº§çš„ä»“ä½ä¸Šé™
# è‚¡ç¥¨æƒé‡æ›´é«˜ï¼Œå€ºåˆ¸æƒé‡é™ä½
ASSET_CLASS_WEIGHTS = {
    "stocks": 1.0,      # è‚¡ç¥¨: 100% æƒé‡ (æœ€é«˜ä¼˜å…ˆ)
    "bonds": 0.3,       # å€ºåˆ¸: 30% æƒé‡ (é™ä½)
    "commodities": 0.6, # å•†å“: 60% æƒé‡
    "reits": 0.5,       # REITs: 50% æƒé‡
    "crypto": 0.4,      # åŠ å¯†è´§å¸: 40% æƒé‡ (é£é™©é«˜)
}

ALL_SYMBOLS = []
for symbols in ASSETS.values():
    ALL_SYMBOLS.extend(symbols)


# ============================================================
# Portfolio Manager
# ============================================================

class Portfolio:
    """æŠ•èµ„ç»„åˆç®¡ç† - å¸¦è¯¦ç»†æ—¥å¿—"""

    def __init__(self, initial_capital: float, logger: logging.Logger):
        self.initial_capital = initial_capital
        self.cash = initial_capital
        self.positions: Dict[str, float] = {}  # symbol -> quantity
        self.position_costs: Dict[str, float] = {}  # symbol -> avg cost
        self.value_history: List[float] = []
        self.date_history: List[str] = []
        self.trade_log: List[Dict] = []
        self.trade_count = 0
        self.transaction_cost_rate = 0.001  # 0.1%
        self.logger = logger

    def get_total_value(self, prices: Dict[str, float]) -> float:
        """è®¡ç®—æ€»ä»·å€¼"""
        total = self.cash
        for symbol, qty in self.positions.items():
            if symbol in prices and qty > 0:
                total += qty * prices[symbol]
        return total

    def execute_trade(
        self,
        symbol: str,
        action: str,
        price: float,
        total_value: float,
        date: str,
        expert_role: str
    ) -> Dict:
        """æ‰§è¡Œäº¤æ˜“å¹¶è®°å½•è¯¦ç»†æ—¥å¿—"""
        result = {
            "date": date,
            "symbol": symbol,
            "action": action,
            "price": price,
            "expert": expert_role,
            "executed": False
        }

        if "HOLD" in action or action == "":
            return result

        # è§£ææ¯”ä¾‹
        pct = 0.25  # é»˜è®¤25%
        if "_" in action:
            parts = action.split("_")
            if len(parts) >= 2:
                pct_str = parts[1].replace("%", "")
                try:
                    pct = int(pct_str) / 100
                except:
                    pct = 0.25

        current_qty = self.positions.get(symbol, 0)

        if "BUY" in action:
            buy_amount = total_value * pct
            shares_to_buy = int(buy_amount / price)
            cost = shares_to_buy * price * (1 + self.transaction_cost_rate)

            if cost <= self.cash and shares_to_buy > 0:
                self.cash -= cost
                old_qty = self.positions.get(symbol, 0)
                old_cost = self.position_costs.get(symbol, 0)

                new_qty = old_qty + shares_to_buy
                new_avg_cost = ((old_qty * old_cost) + (shares_to_buy * price)) / new_qty if new_qty > 0 else 0

                self.positions[symbol] = new_qty
                self.position_costs[symbol] = new_avg_cost
                self.trade_count += 1

                result["executed"] = True
                result["shares"] = shares_to_buy
                result["cost"] = cost
                result["new_position"] = new_qty

                self.logger.debug(
                    f"BUY {symbol}: {shares_to_buy} shares @ ${price:.2f} = ${cost:.2f}, "
                    f"new position: {new_qty} shares"
                )

        elif "SELL" in action:
            if current_qty > 0:
                shares_to_sell = int(current_qty * pct)
                if shares_to_sell > 0:
                    proceeds = shares_to_sell * price * (1 - self.transaction_cost_rate)
                    self.cash += proceeds
                    self.positions[symbol] = current_qty - shares_to_sell
                    self.trade_count += 1

                    # è®¡ç®—ç›ˆäº
                    avg_cost = self.position_costs.get(symbol, price)
                    pnl = (price - avg_cost) * shares_to_sell

                    result["executed"] = True
                    result["shares"] = shares_to_sell
                    result["proceeds"] = proceeds
                    result["pnl"] = pnl
                    result["new_position"] = current_qty - shares_to_sell

                    self.logger.debug(
                        f"SELL {symbol}: {shares_to_sell} shares @ ${price:.2f} = ${proceeds:.2f}, "
                        f"PnL: ${pnl:.2f}, remaining: {current_qty - shares_to_sell} shares"
                    )

        if result["executed"]:
            self.trade_log.append(result)

        return result

    def record_value(self, prices: Dict[str, float], date: str):
        """è®°å½•å½“å‰ç»„åˆä»·å€¼"""
        value = self.get_total_value(prices)
        self.value_history.append(value)
        self.date_history.append(date)

    def get_metrics(self) -> Dict:
        """è®¡ç®—ç»©æ•ˆæŒ‡æ ‡"""
        if len(self.value_history) < 2:
            return {}

        values = np.array(self.value_history)
        returns = np.diff(values) / values[:-1]

        total_return = (values[-1] / values[0]) - 1

        # å¹´åŒ–æ”¶ç›Šç‡ (å‡è®¾252äº¤æ˜“æ—¥)
        days = len(values)
        annualized_return = (1 + total_return) ** (252 / days) - 1 if days > 0 else 0

        # æ³¢åŠ¨ç‡
        volatility = np.std(returns) * np.sqrt(252) if len(returns) > 0 else 0

        # å¤æ™®æ¯”ç‡ (å‡è®¾æ— é£é™©åˆ©ç‡4%)
        rf = 0.04 / 252
        excess_returns = returns - rf
        sharpe = np.mean(excess_returns) / np.std(excess_returns) * np.sqrt(252) if np.std(excess_returns) > 0 else 0

        # æœ€å¤§å›æ’¤
        peak = np.maximum.accumulate(values)
        drawdown = (values - peak) / peak
        max_drawdown = np.min(drawdown)

        # Sortinoæ¯”ç‡
        downside_returns = excess_returns[excess_returns < 0]
        downside_std = np.std(downside_returns) * np.sqrt(252) if len(downside_returns) > 0 else 0
        sortino = np.mean(excess_returns) * 252 / downside_std if downside_std > 0 else 0

        # Calmaræ¯”ç‡
        calmar = annualized_return / abs(max_drawdown) if max_drawdown != 0 else 0

        # èƒœç‡
        winning_trades = sum(1 for t in self.trade_log if t.get("pnl", 0) > 0)
        total_trades_with_pnl = sum(1 for t in self.trade_log if "pnl" in t)
        win_rate = winning_trades / total_trades_with_pnl if total_trades_with_pnl > 0 else 0

        return {
            "total_return": total_return,
            "annualized_return": annualized_return,
            "volatility": volatility,
            "sharpe_ratio": sharpe,
            "sortino_ratio": sortino,
            "calmar_ratio": calmar,
            "max_drawdown": max_drawdown,
            "total_trades": self.trade_count,
            "win_rate": win_rate,
            "final_value": values[-1],
            "initial_value": values[0],
        }


# ============================================================
# æ•°æ®è·å–
# ============================================================

def fetch_market_data(start_date: str, end_date: str, logger: logging.Logger) -> pd.DataFrame:
    """è·å–å¸‚åœºæ•°æ® (ä½¿ç”¨ FMP API)"""
    from finsage.data.fmp_client import FMPClient

    logger.info(f"Fetching data for {len(ALL_SYMBOLS)} symbols from {start_date} to {end_date}")

    client = FMPClient()

    all_data = {}
    for symbol in ALL_SYMBOLS:
        try:
            df = client.get_historical_price(symbol, start_date, end_date)
            if df is not None and not df.empty:
                if 'close' in df.columns:
                    all_data[symbol] = df['close']
                elif 'Close' in df.columns:
                    all_data[symbol] = df['Close']
                logger.debug(f"  {symbol}: {len(df)} days")
        except Exception as e:
            logger.warning(f"  {symbol}: failed - {e}")

    if not all_data:
        logger.error("No data fetched!")
        return pd.DataFrame()

    prices = pd.DataFrame(all_data)
    prices = prices.ffill().bfill()
    logger.info(f"Got {len(prices)} trading days of data for {len(all_data)} symbols")

    return prices


def create_market_observation(
    date: str,
    prices: pd.Series,
    history: pd.DataFrame,
    portfolio: Portfolio,
    logger: logging.Logger
) -> str:
    """åˆ›å»ºè¯¦ç»†çš„å¸‚åœºè§‚å¯Ÿ"""

    obs_parts = [
        f"## å¸‚åœºæ—¥æœŸ: {date}",
        f"## èµ„äº§ç±»åˆ«: multi-asset",
        f"## ç»„åˆä»·å€¼: ${portfolio.get_total_value(prices.to_dict()):,.2f}",
        ""
    ]

    for asset_class, symbols in ASSETS.items():
        obs_parts.append(f"### {asset_class.upper()}")
        for symbol in symbols:
            if symbol in prices.index:
                price = prices[symbol]

                if symbol in history.columns:
                    hist = history[symbol].dropna()
                    if len(hist) > 14:
                        # æ—¥æ¶¨è·Œ
                        change = (hist.iloc[-1] / hist.iloc[-2] - 1) * 100 if len(hist) > 1 else 0

                        # RSI
                        delta = hist.diff()
                        gain = delta.where(delta > 0, 0).rolling(14).mean()
                        loss = (-delta.where(delta < 0, 0)).rolling(14).mean()
                        rs = gain / loss
                        rsi = 100 - (100 / (1 + rs.iloc[-1])) if not pd.isna(rs.iloc[-1]) else 50

                        # SMA
                        sma_20 = hist.rolling(20).mean().iloc[-1] if len(hist) >= 20 else price
                        sma_trend = "above" if price > sma_20 else "below"

                        # æŒä»“ä¿¡æ¯
                        position = portfolio.positions.get(symbol, 0)
                        position_str = f", æŒä»“: {position}" if position > 0 else ""

                        obs_parts.append(
                            f"- {symbol}: ${price:.2f}, æ—¥æ¶¨è·Œ: {change:+.2f}%, RSI: {rsi:.1f}, "
                            f"SMA20: {sma_trend}{position_str}"
                        )
                    else:
                        obs_parts.append(f"- {symbol}: ${price:.2f}")
                else:
                    obs_parts.append(f"- {symbol}: ${price:.2f}")

    # å®è§‚ç¯å¢ƒ
    spy_trend = "ä¹è§‚"
    if "SPY" in history.columns and len(history["SPY"]) >= 5:
        spy_trend = "ä¹è§‚" if prices.get("SPY", 0) > history["SPY"].iloc[-5] else "è°¨æ…"

    obs_parts.extend([
        "",
        "### å®è§‚ç¯å¢ƒ",
        f"- å¸‚åœºæƒ…ç»ª: {spy_trend}",
    ])

    return "\n".join(obs_parts)


# ============================================================
# Main Evaluation
# ============================================================

def run_evaluation(
    checkpoint_name: str,
    test_start: str,
    test_end: str,
    initial_capital: float = 1_000_000,
    rebalance_freq: int = 5,
    model_path: str = "Qwen/Qwen2.5-14B-Instruct",
    log_dir: str = "results",
    load_in_4bit: bool = False,
):
    """è¿è¡Œè¯„ä¼°

    Args:
        load_in_4bit: ä½¿ç”¨4-bité‡åŒ–ï¼Œé€‚åˆ24GBæ˜¾å­˜GPU (RTX 3090/4090)
    """

    # è®¾ç½®æ—¥å¿—
    os.makedirs(log_dir, exist_ok=True)
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    # ä½¿ç”¨checkpointç›®å½•çš„æœ€åä¸¤çº§ä½œä¸ºåç§° (å¦‚ marft_v4_aggressive/epoch_2)
    checkpoint_basename = os.path.basename(checkpoint_name.rstrip('/'))
    if os.path.isabs(checkpoint_name):
        parent = os.path.basename(os.path.dirname(checkpoint_name.rstrip('/')))
        checkpoint_basename = f"{parent}_{checkpoint_basename}"
    log_file = os.path.join(log_dir, f"eval_{checkpoint_basename}_{timestamp}.log")
    logger = setup_detailed_logging(log_file)

    logger.info("=" * 80)
    logger.info(" MARFT V4 LoRA æƒé‡è¯„ä¼°")
    logger.info("=" * 80)
    logger.info(f" Checkpoint: {checkpoint_name}")
    logger.info(f" æµ‹è¯•æ—¶é—´: {test_start} ~ {test_end}")
    logger.info(f" åˆå§‹èµ„é‡‘: ${initial_capital:,.2f}")
    logger.info(f" å†å¹³è¡¡é¢‘ç‡: æ¯{rebalance_freq}å¤©")
    logger.info(f" æ¨¡å‹: {model_path}")
    logger.info(f" æ—¥å¿—æ–‡ä»¶: {log_file}")
    logger.info("=" * 80)

    # Checkpointè·¯å¾„ - æ”¯æŒç»å¯¹è·¯å¾„æˆ–ç›¸å¯¹äºcheckpoints_trainedçš„åç§°
    if os.path.isabs(checkpoint_name) or checkpoint_name.startswith("/"):
        checkpoint_dir = checkpoint_name
    else:
        project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
        checkpoint_dir = os.path.join(project_root, "checkpoints_trained", checkpoint_name)

    if not os.path.exists(checkpoint_dir):
        logger.error(f"Checkpointç›®å½•ä¸å­˜åœ¨: {checkpoint_dir}")
        return None

    logger.info(f"Checkpointç›®å½•: {checkpoint_dir}")

    # æ£€æŸ¥adapteræ–‡ä»¶
    adapters_found = []
    for role in ["Stock_Expert", "Bond_Expert", "Commodity_Expert", "REITs_Expert",
                 "Crypto_Expert", "Portfolio_Manager", "Hedging_Agent",
                 "Position_Sizing_Agent", "Risk_Controller"]:
        adapter_path = os.path.join(checkpoint_dir, role, role, "adapter_model.safetensors")
        if os.path.exists(adapter_path):
            size_mb = os.path.getsize(adapter_path) / 1024 / 1024
            adapters_found.append(role)
            logger.debug(f"  Found {role}: {size_mb:.1f} MB")

    logger.info(f"æ‰¾åˆ° {len(adapters_found)} ä¸ª LoRA é€‚é…å™¨")

    # è·å–å¸‚åœºæ•°æ®
    logger.info("\nè·å–å¸‚åœºæ•°æ®...")
    prices_df = fetch_market_data(test_start, test_end, logger)
    trading_days = prices_df.index.tolist()

    if len(trading_days) < 2:
        logger.error("æ•°æ®ä¸è¶³ï¼Œæ— æ³•è¯„ä¼°")
        return None

    logger.info(f"å…± {len(trading_days)} ä¸ªäº¤æ˜“æ—¥")

    # æ£€æŸ¥GPU
    if not torch.cuda.is_available():
        logger.error("CUDAä¸å¯ç”¨!")
        return None

    logger.info(f"\nGPU: {torch.cuda.get_device_name(0)}")
    logger.info(f"GPUæ˜¾å­˜: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB")

    # åŠ è½½æ¨¡å‹
    logger.info("\nåŠ è½½LLM Expert Manager...")
    from finsage.rl.shared_expert_manager import SharedModelExpertManager

    manager = SharedModelExpertManager(
        model_path=model_path,
        device="cuda:0",
        bf16=not load_in_4bit,  # 4bitæ—¶ä¸ç”¨bf16
        load_in_4bit=load_in_4bit,  # æ”¯æŒ24GB GPU
        use_gradient_checkpointing=False,  # è¯„ä¼°æ—¶ä¸éœ€è¦
    )

    logger.info(f"åŸºç¡€æ¨¡å‹åŠ è½½å®Œæˆ, GPU Memory: {torch.cuda.memory_allocated() / 1e9:.1f} GB")

    # åŠ è½½è®­ç»ƒå¥½çš„LoRAæƒé‡
    logger.info(f"\nåŠ è½½è®­ç»ƒå¥½çš„LoRAæƒé‡: {checkpoint_dir}")
    manager.load_adapters(checkpoint_dir)
    logger.info(f"LoRAæƒé‡åŠ è½½å®Œæˆ, GPU Memory: {torch.cuda.memory_allocated() / 1e9:.1f} GB")

    # è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼
    manager.eval()

    # åˆ›å»ºç»„åˆ
    portfolio = Portfolio(initial_capital, logger)

    # åˆ›å»ºBugè¿½è¸ªå™¨
    bug_tracker = BugTracker(logger)

    # æœŸæœ›çš„å®Œæ•´Expertåˆ—è¡¨ (9ä¸ª)
    EXPECTED_EXPERTS = [
        "Stock_Expert", "Bond_Expert", "Commodity_Expert", "REITs_Expert", "Crypto_Expert",
        "Portfolio_Manager", "Hedging_Agent", "Position_Sizing_Agent", "Risk_Controller"
    ]

    # è¯„ä¼°å¾ªç¯
    logger.info("\n" + "=" * 80)
    logger.info(" å¼€å§‹è¯„ä¼° (å¢å¼ºBugæ£€æµ‹)")
    logger.info("=" * 80)
    logger.info(f" æœŸæœ›çš„Experts: {EXPECTED_EXPERTS}")

    decision_log = []
    # åˆå§‹åŒ–æ‰€æœ‰9ä¸ªExpertçš„ç»Ÿè®¡ (ä¸ä»…ä»…æ˜¯æ‰¾åˆ°çš„adapters)
    expert_stats = {role: {"calls": 0, "actions": {}, "avg_confidence": []} for role in EXPECTED_EXPERTS}

    for i, date in enumerate(trading_days):
        date_str = date.strftime("%Y-%m-%d")
        prices = prices_df.loc[date]

        # è®°å½•ç»„åˆä»·å€¼
        price_dict = {s: prices[s] for s in ALL_SYMBOLS if s in prices.index}
        portfolio.record_value(price_dict, date_str)

        # æ˜¯å¦éœ€è¦rebalance
        if i % rebalance_freq != 0 and i > 0:
            continue

        # è·å–å†å²æ•°æ®
        lookback = min(i + 1, 30)
        history = prices_df.iloc[max(0, i-lookback):i+1]

        # åˆ›å»ºå¸‚åœºè§‚å¯Ÿ
        obs = create_market_observation(date_str, prices, history, portfolio, logger)

        # æ£€æŸ¥è¾“å…¥æ•°æ®é—®é¢˜
        bug_tracker.check_data_issues(obs, date_str, history=history)

        current_value = portfolio.get_total_value(price_dict)
        logger.info(f"\n[{date_str}] ç»„åˆä»·å€¼: ${current_value:,.2f} (æ”¶ç›Š: {(current_value/initial_capital-1)*100:+.2f}%)")

        # è·å–Expertå†³ç­–
        start_time = time.time()
        try:
            all_actions = manager.run_expert_chain(obs)
            chain_success = True
        except Exception as e:
            bug_tracker.log_issue("EXPERT_CHAIN_ERROR",
                                 f"Expert Chain æ‰§è¡Œå¤±è´¥: {str(e)}",
                                 severity="ERROR", date=date_str,
                                 extra={"traceback": traceback.format_exc()})
            all_actions = {}
            chain_success = False

        inference_time = time.time() - start_time

        logger.debug(f"æ¨ç†æ—¶é—´: {inference_time:.2f}s")

        # éªŒè¯Expert Chainå®Œæ•´æ€§
        if chain_success:
            bug_tracker.validate_expert_chain(all_actions, EXPECTED_EXPERTS)
            logger.info(f"  Expert Chain è¿”å› {len(all_actions)} ä¸ªExperts: {list(all_actions.keys())}")

        # è®°å½•Expertå†³ç­–
        daily_decisions = {}

        # ============================================================
        # ç¬¬ä¸€æ­¥: æ”¶é›†æ‰€æœ‰Expertå†³ç­–å’ŒMeta-Level Agentå»ºè®®
        # ============================================================
        asset_expert_actions = {}  # 5ä¸ªèµ„äº§ç±»åˆ«Expertçš„åŠ¨ä½œ
        meta_agent_outputs = {}    # 4ä¸ªMeta-Level Agentçš„è¾“å‡º

        for role, action_dict in all_actions.items():
            action = action_dict.get("action", "HOLD")
            confidence = action_dict.get("confidence", 0.5)
            reasoning = action_dict.get("reasoning", "")[:100]

            daily_decisions[role] = action

            # Bugè¿½è¸ª: è®°å½•æ¯ä¸ªExpertè°ƒç”¨
            bug_tracker.track_expert_call(role, success=True, output=action_dict)

            # æ›´æ–°ç»Ÿè®¡ (æ‰€æœ‰9ä¸ªExpert)
            if role in expert_stats:
                expert_stats[role]["calls"] += 1
                expert_stats[role]["actions"][action] = expert_stats[role]["actions"].get(action, 0) + 1
                expert_stats[role]["avg_confidence"].append(confidence)

            logger.debug(f"  {role}: {action} (conf={confidence:.2f}) - {reasoning}...")

            # åŒºåˆ†Asset Expertså’ŒMeta-Level Agents
            if role in ["Stock_Expert", "Bond_Expert", "Commodity_Expert", "REITs_Expert", "Crypto_Expert"]:
                asset_expert_actions[role] = action_dict
            else:
                meta_agent_outputs[role] = action_dict
                # éªŒè¯Meta-Level Agentè¾“å‡ºæ ¼å¼
                bug_tracker.validate_meta_agent_output(role, action_dict, date_str)

        # ============================================================
        # ç¬¬äºŒæ­¥: å¤„ç†Meta-Level Agentçš„è¾“å‡º
        # ============================================================

        # Risk_Controller: æ£€æŸ¥æ˜¯å¦æœ‰veto (å¦å†³äº¤æ˜“)
        risk_veto = False
        if "Risk_Controller" in meta_agent_outputs:
            risk_output = meta_agent_outputs["Risk_Controller"]
            risk_veto = risk_output.get("veto", False)
            if risk_veto:
                logger.warning(f"  [RISK] Risk_Controller å¦å†³æœ¬è½®äº¤æ˜“!")

        # Position_Sizing_Agent: è·å–ä»“ä½è°ƒæ•´å»ºè®®
        position_scale = 0.5  # é»˜è®¤ä½¿ç”¨ 50% èµ„é‡‘
        if "Position_Sizing_Agent" in meta_agent_outputs:
            pos_output = meta_agent_outputs["Position_Sizing_Agent"]
            # æ ¹æ®risk_budgetè°ƒæ•´ä»“ä½
            risk_budget = pos_output.get("risk_budget", 0.5)
            if isinstance(risk_budget, (int, float)) and 0 < risk_budget <= 1:
                # ä¿æŠ¤: å¦‚æœ risk_budget å¤ªå° (< 0.1)ï¼Œä½¿ç”¨é»˜è®¤å€¼ 0.5
                # é¿å…å› ä¸ºæ¨¡å‹è¾“å‡ºè¿‡äºä¿å®ˆå¯¼è‡´ä»“ä½è¿‡å°
                if risk_budget < 0.1:
                    logger.warning(f"  [POSITION] risk_budget={risk_budget:.2f} å¤ªå°ï¼Œä½¿ç”¨é»˜è®¤å€¼ 0.5")
                    position_scale = 0.5
                else:
                    position_scale = risk_budget
                logger.info(f"  [POSITION] ä»“ä½ç¼©æ”¾ç³»æ•°: {position_scale:.2f}")

        # Portfolio_Manager: è®°å½•æ•´ä½“é…ç½®å»ºè®®
        if "Portfolio_Manager" in meta_agent_outputs:
            pm_output = meta_agent_outputs["Portfolio_Manager"]
            target_alloc = pm_output.get("target_allocation", {})
            if target_alloc:
                logger.info(f"  [PM] ç›®æ ‡é…ç½®: {target_alloc}")

        # Hedging_Agent: è®°å½•å¯¹å†²å»ºè®®
        if "Hedging_Agent" in meta_agent_outputs:
            hedge_output = meta_agent_outputs["Hedging_Agent"]
            hedge_strategy = hedge_output.get("hedge_strategy", "none")
            logger.info(f"  [HEDGE] å¯¹å†²ç­–ç•¥: {hedge_strategy}")

        # ============================================================
        # ç¬¬ä¸‰æ­¥: æ‰§è¡Œäº¤æ˜“ (å¦‚æœæœªè¢«Risk_Controllerå¦å†³)
        # ============================================================
        if risk_veto:
            logger.info("  [SKIP] æœ¬è½®äº¤æ˜“è¢«é£æ§å¦å†³ï¼Œè·³è¿‡æ‰§è¡Œ")
        else:
            for role, action_dict in asset_expert_actions.items():
                action = action_dict.get("action", "HOLD")

                # æ ¹æ®Expertç±»å‹å†³å®šäº¤æ˜“å“ªäº›èµ„äº§
                asset_class = role.split("_")[0].lower()
                if asset_class == "stock":
                    symbols = ASSETS.get("stocks", [])
                    class_key = "stocks"
                elif asset_class == "bond":
                    symbols = ASSETS.get("bonds", [])
                    class_key = "bonds"
                elif asset_class == "commodity":
                    symbols = ASSETS.get("commodities", [])
                    class_key = "commodities"
                elif asset_class == "reits":
                    symbols = ASSETS.get("reits", [])
                    class_key = "reits"
                elif asset_class == "crypto":
                    symbols = ASSETS.get("crypto", [])
                    class_key = "crypto"
                else:
                    continue

                # è·å–èµ„äº§ç±»åˆ«æƒé‡ (æ§åˆ¶è¯¥ç±»èµ„äº§çš„ä»“ä½æ¯”ä¾‹)
                class_weight = ASSET_CLASS_WEIGHTS.get(class_key, 1.0)

                # å¯¹æ¯ä¸ªèµ„äº§æ‰§è¡Œç›¸åŒåŠ¨ä½œ (åº”ç”¨ä»“ä½ç¼©æ”¾ + èµ„äº§ç±»åˆ«æƒé‡)
                for symbol in symbols:
                    if symbol in price_dict:
                        # æ ¹æ®Position_Sizingå’Œèµ„äº§ç±»åˆ«æƒé‡è°ƒæ•´äº¤æ˜“è§„æ¨¡
                        scaled_value = current_value * position_scale * class_weight
                        result = portfolio.execute_trade(
                            symbol=symbol,
                            action=action,
                            price=price_dict[symbol],
                            total_value=scaled_value,
                            date=date_str,
                            expert_role=role
                        )
                        if result["executed"]:
                            logger.info(f"  {role} -> {symbol}: {action} (class_weight={class_weight:.1f})")

        decision_log.append({
            "date": date_str,
            "portfolio_value": current_value,
            "decisions": daily_decisions,
            "inference_time": inference_time
        })

    # è®¡ç®—æœ€ç»ˆæŒ‡æ ‡
    metrics = portfolio.get_metrics()

    # Expertç»Ÿè®¡æ‘˜è¦
    logger.info("\n" + "=" * 80)
    logger.info(" Expert å†³ç­–ç»Ÿè®¡")
    logger.info("=" * 80)
    for role, stats in expert_stats.items():
        if stats["calls"] > 0:
            avg_conf = np.mean(stats["avg_confidence"]) if stats["avg_confidence"] else 0
            logger.info(f"\n{role}:")
            logger.info(f"  è°ƒç”¨æ¬¡æ•°: {stats['calls']}")
            logger.info(f"  å¹³å‡ç½®ä¿¡åº¦: {avg_conf:.3f}")
            logger.info(f"  åŠ¨ä½œåˆ†å¸ƒ: {stats['actions']}")

    # è¾“å‡ºæœ€ç»ˆç»“æœ
    logger.info("\n" + "=" * 80)
    logger.info(" è¯„ä¼°ç»“æœ")
    logger.info("=" * 80)
    logger.info(f" Checkpoint: {checkpoint_name}")
    logger.info(f" æµ‹è¯•æœŸé—´: {test_start} ~ {test_end}")
    logger.info(f" åˆå§‹èµ„é‡‘: ${initial_capital:,.2f}")
    logger.info(f" æœ€ç»ˆä»·å€¼: ${metrics.get('final_value', 0):,.2f}")
    logger.info(f" æ€»æ”¶ç›Šç‡: {metrics.get('total_return', 0)*100:.2f}%")
    logger.info(f" å¹´åŒ–æ”¶ç›Š: {metrics.get('annualized_return', 0)*100:.2f}%")
    logger.info(f" å¤æ™®æ¯”ç‡: {metrics.get('sharpe_ratio', 0):.2f}")
    logger.info(f" Sortinoæ¯”ç‡: {metrics.get('sortino_ratio', 0):.2f}")
    logger.info(f" Calmaræ¯”ç‡: {metrics.get('calmar_ratio', 0):.2f}")
    logger.info(f" æœ€å¤§å›æ’¤: {metrics.get('max_drawdown', 0)*100:.2f}%")
    logger.info(f" æ³¢åŠ¨ç‡: {metrics.get('volatility', 0)*100:.2f}%")
    logger.info(f" äº¤æ˜“æ¬¡æ•°: {metrics.get('total_trades', 0)}")
    logger.info(f" èƒœç‡: {metrics.get('win_rate', 0)*100:.1f}%")
    logger.info("=" * 80)

    # æ‰“å°Bugæ£€æµ‹æŠ¥å‘Š
    bug_summary = bug_tracker.print_summary()

    # ä¿å­˜ç»“æœ
    result = {
        "checkpoint": checkpoint_name,
        "test_start": test_start,
        "test_end": test_end,
        "initial_capital": initial_capital,
        "model_path": model_path,
        "metrics": metrics,
        "portfolio_values": portfolio.value_history,
        "dates": portfolio.date_history,
        "decisions": decision_log,
        "expert_stats": {k: {**v, "avg_confidence": float(np.mean(v["avg_confidence"])) if v["avg_confidence"] else 0}
                        for k, v in expert_stats.items()},
        "trade_log": portfolio.trade_log,
        "bug_detection": {
            "total_issues": bug_summary["total_issues"],
            "issues_by_category": bug_summary["issues_by_category"],
            "expert_call_counts": bug_summary["expert_call_counts"],
            "meta_agent_analysis": bug_summary["meta_agent_analysis"],
            "critical_bugs_found": any(
                bug_summary["expert_call_counts"].get(agent, 0) == 0
                for agent in ["Portfolio_Manager", "Hedging_Agent", "Position_Sizing_Agent", "Risk_Controller"]
            )
        }
    }

    result_file = os.path.join(log_dir, f"eval_{checkpoint_basename}_{timestamp}.json")
    with open(result_file, "w") as f:
        json.dump(result, f, indent=2, default=str)
    logger.info(f"\nç»“æœå·²ä¿å­˜: {result_file}")
    logger.info(f"æ—¥å¿—å·²ä¿å­˜: {log_file}")

    return result


def main():
    import argparse
    parser = argparse.ArgumentParser(description="è¯„ä¼°è®­ç»ƒå¥½çš„MARFT V4 LoRAæƒé‡")
    parser.add_argument("--checkpoint", default="aggressive_final",
                       help="Checkpointåç§° (aggressive_final æˆ– balanced_final)")
    parser.add_argument("--test-start", default="2024-07-01", help="æµ‹è¯•å¼€å§‹æ—¥æœŸ")
    parser.add_argument("--test-end", default="2024-12-31", help="æµ‹è¯•ç»“æŸæ—¥æœŸ")
    parser.add_argument("--capital", type=float, default=1_000_000, help="åˆå§‹èµ„é‡‘")
    parser.add_argument("--freq", type=int, default=1, help="å†å¹³è¡¡é¢‘ç‡(å¤©), 1=æ¯å¤©å†³ç­–")
    parser.add_argument("--model", default="Qwen/Qwen2.5-14B-Instruct", help="åŸºç¡€æ¨¡å‹")
    parser.add_argument("--log-dir", default="results", help="æ—¥å¿—è¾“å‡ºç›®å½•")
    parser.add_argument("--4bit", dest="load_4bit", action="store_true",
                       help="ä½¿ç”¨4-bité‡åŒ– (é€‚åˆ24GBæ˜¾å­˜GPU)")
    args = parser.parse_args()

    run_evaluation(
        checkpoint_name=args.checkpoint,
        test_start=args.test_start,
        test_end=args.test_end,
        initial_capital=args.capital,
        rebalance_freq=args.freq,
        model_path=args.model,
        log_dir=args.log_dir,
        load_in_4bit=args.load_4bit,
    )


if __name__ == "__main__":
    main()
